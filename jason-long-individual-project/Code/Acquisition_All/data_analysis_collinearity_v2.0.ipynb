{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking for collinearity and/or multicollinearity "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "Pandas documentation\n",
    "Previous code    \n",
    "https://chrisalbon.com/python/data_wrangling/pandas_dropping_column_and_rows/    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#non anaconda native modules, these will need the conda env (listed above) or pip install\n",
    "import pydash as __\n",
    "import seaborn as sns\n",
    "\n",
    "#custom modules\n",
    "from utils import \\\n",
    "ModelTester, \\\n",
    "to_important_features, \\\n",
    "create_heatmap, \\\n",
    "create_learning_curve, \\\n",
    "plot_learning_curve\n",
    "\n",
    "# pre-processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import \\\n",
    "StandardScaler, \\\n",
    "LabelEncoder\n",
    "\n",
    "#classifiers:\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# ta-lib\n",
    "import talib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACQUISITION_RAW_COLUMN_NAMES = ['loan_id', 'origin_channel', 'seller_name', 'original_interest_rate', 'original_upb',\n",
    "                                'original_loan_term', 'origination_date_string', 'first_payment_date_string',\n",
    "                                'original_loan_to_value', 'original_combined_loan_to_value', 'number_of_borrowers',\n",
    "                                'original_debt_to_income_ratio', 'borrower_credit_score_at_origination',\n",
    "                                'first_time_homebuyer_indicator', 'loan_purpose', 'property_type', 'number_of_units',\n",
    "                                'occupancy_type', 'property_state', 'zip_code_short',\n",
    "                                'primary_mortgage_insurance_percent',\n",
    "                                'product_type', 'co_borrower_credit_score_at_origination', 'mortgage_insurance_type',\n",
    "                                'relocation_mortgage_indicator', 'sdq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Acquisition_2016Q1.txt', sep=\"|\", index_col=False, names=ACQUISITION_RAW_COLUMN_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert original_upb to float for ta-lib to function correctly\n",
    "\n",
    "convert_dict = {'original_upb': float, \n",
    "                } \n",
    "  \n",
    "df = df.astype(convert_dict)\n",
    "\n",
    "# reference material: https://www.geeksforgeeks.org/change-data-type-for-one-or-more-columns-in-pandas-dataframe/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_talib_indicators(col):\n",
    "    # adding momentum and volume indicators\n",
    "    fastk, fastd = talib.STOCHRSI(col)\n",
    "    macd, macdsignal, macdhist = talib.MACD(col)\n",
    "    dema = talib.DEMA(col) \n",
    "    roc = talib.ROC(col)\n",
    "    return pd.DataFrame(\n",
    "        dict(fastk=fastk,\n",
    "             fastd=fastd,\n",
    "             stochrsi=fastd-fastk,\n",
    "             macdhist=macdhist,\n",
    "             dema=dema,\n",
    "             roc=roc\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    df,\n",
    "    add_talib_indicators(df.original_upb.as_matrix())\n",
    "], axis=1) \\\n",
    ".set_index('loan_id') \\\n",
    ".sort_index()\n",
    "\n",
    "# # if unable to install/load talib use, uncomment and use:\n",
    "# # df = pd.read_table('./data/ETH_USD_data_with_indicators.csv', sep=',', memory_map=True, parse_dates=True, date_parser=date_parser, index_col='date').sort_index()\n",
    "# df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['relocation_mortgage_indicator'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['relocation_mortgage_indicator'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the object types\n",
    "df.drop(df.select_dtypes(['object']), inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('sdq', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the remaining to floats\n",
    "\n",
    "# convert original_upb to float for ta-lib to function correctly\n",
    "\n",
    "df = df.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(df.columns)\n",
    "# our target is the following hour, \n",
    "# specifically whether it went up (1) or down (0) from the period close an hour before.\n",
    "# we drop the last row since the target will be NaN (the next hour is the future.)\n",
    "y = np.where(df.number_of_units.shift(-1) > df.number_of_units, 1, 0)[:-1]\n",
    "X = df[features].fillna(0)[:-1]\n",
    "X.tail()\n",
    "\n",
    "# features = list(filter(lambda x: x not in ['target', 'date', 'symbol' ,'close', 'high', 'open', 'close', 'low'] , df.columns))\n",
    "# # our target is the following hour, \n",
    "# # specifically whether it went up (1) or down (0) from the period close an hour before.\n",
    "# # we drop the last row since the target will be NaN (the next hour is the future.)\n",
    "# y = np.where(df.close.shift(-1) > df.close, 1, 0)[:-1]\n",
    "# X = df[features].fillna(0)[:-1]\n",
    "# X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(X, height=len(features))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_heatmap(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, KNeighborsClassifier]\n",
    "clf_args = {\n",
    "    '0': dict(random_state=0, C=100, penalty='l1', solver='saga', n_jobs=1), \n",
    "    '1': dict(random_state=0),\n",
    "    '2': dict(random_state=0, n_estimators=30, n_jobs=1),\n",
    "    '3': dict(n_neighbors=5, p=2, metric='minkowski', n_jobs=1),\n",
    "            }\n",
    "# # Original\n",
    "# clfs = [LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, KNeighborsClassifier, SVC]\n",
    "# clf_args = {\n",
    "#     '0': dict(random_state=0, C=100, penalty='l1', solver='saga', n_jobs=1), \n",
    "#     '1': dict(random_state=0),\n",
    "#     '2': dict(random_state=0, n_estimators=30, n_jobs=1),\n",
    "#     '3': dict(n_neighbors=5, p=2, metric='minkowski', n_jobs=1),\n",
    "#     '4': dict(random_state=0),\n",
    "#             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = ModelTester(clfs,\n",
    "                     X=X,\n",
    "                     y=y,\n",
    "                     clf_args={**clf_args, **{'0': dict(solver='newton-cg')}},\n",
    "                     x_normalizer=StandardScaler\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(tester.run_tests(default_args={}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester.plot_fscores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tester.plot_importances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select important features which score >= 1 std deviation\n",
    "min_top_imp = __.reduce_(tester.feature_importances, to_important_features(std_dev_mult=1), {})\n",
    "min_top_imp_names = list(min_top_imp.keys())\n",
    "min_top_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the models again using the feature subset on X\n",
    "tester_feature_sub = ModelTester(\n",
    "     clfs,\n",
    "     X=X[min_top_imp_names],\n",
    "     y=y,\n",
    "     clf_args=clf_args,\n",
    "     x_normalizer=StandardScaler)\n",
    "\n",
    "results_feature_sub = list(tester_feature_sub.run_tests(default_args={}))\n",
    "tester_feature_sub.plot_fscores() \n",
    "# models seem to have done worse on the subset :(, \n",
    "#which would make some sense considering how even most of the importance scores were"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y into multiple class targets, \n",
    "# classes are built by getting the difference between the close by 1 hr, then rounding to nearest 10.\n",
    "# we then label encode\n",
    "y2_str = np.round(df.number_of_units.shift(-1) - df.number_of_units, decimals=-1)[:-1].map('{:,.0f}'.format)\n",
    "class_le = LabelEncoder()\n",
    "y2 = class_le.fit_transform(y2_str)\n",
    "unq, counts = np.unique(y2_str, return_counts=True)\n",
    "\n",
    "print('multiclass')\n",
    "print(pd.DataFrame([counts], columns=unq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X.reset_index().drop('date', axis=1), y, test_size=0.3, random_state=0, stratify=y)\n",
    "\n",
    "# ss = StandardScaler()\n",
    "# X_train_std = ss.fit_transform(X_train)\n",
    "# X_test_std = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from pprint import pprint\n",
    "\n",
    "# rf_random_grid = {\n",
    "#     'n_estimators': [int(x) for x in np.linspace(start = 30, stop = 500, num = 10)],\n",
    "#     'max_features': ['auto', 'sqrt'],\n",
    "#     'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)] + [None],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'bootstrap': [True, False]\n",
    "# }\n",
    "\n",
    "# pprint(rf_random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hyper parameter tuning for randomforest\n",
    "# rf = RandomForestClassifier(random_state=0)\n",
    "# rf_random = RandomizedSearchCV(estimator = rf, param_distributions = rf_random_grid, n_iter = 100, cv = 2, random_state=0, n_jobs = -1)\n",
    "# rf_random.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
